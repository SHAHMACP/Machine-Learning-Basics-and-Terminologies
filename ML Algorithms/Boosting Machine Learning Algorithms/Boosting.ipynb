{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **GRADIENT BOOSTING CLASSIFIER ALGORITHM**"
      ],
      "metadata": {
        "id": "3_28Z6QqS7Hh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSw7151tCBs8",
        "outputId": "62449383-b257-4521-81d2-a046784e98b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Classifier accuracy is : 0.98\n"
          ]
        }
      ],
      "source": [
        "# Import models and utility functions\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "\n",
        "\n",
        "# Importing the dataset\n",
        "X, y = load_digits(return_X_y=True)\n",
        "\n",
        "# Splitting dataset\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\ttest_size = 0.25,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\trandom_state = 23)\n",
        "\n",
        "# Instantiate Gradient Boosting Regressor\n",
        "gbc = GradientBoostingClassifier(n_estimators=300,\n",
        "\t\t\t\t\t\t\t\tlearning_rate=0.05,\n",
        "\t\t\t\t\t\t\t\trandom_state=100,\n",
        "\t\t\t\t\t\t\t\tmax_features=5 )\n",
        "# Fit to training set\n",
        "gbc.fit(train_X, train_y)\n",
        "\n",
        "# Predict on test set\n",
        "pred_y = gbc.predict(test_X)\n",
        "\n",
        "# accuracy\n",
        "acc = accuracy_score(test_y, pred_y)\n",
        "print(\"Gradient Boosting Classifier accuracy is : {:.2f}\".format(acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Gradient Boosting Model with restricted parameters\n",
        "gbm = GradientBoostingClassifier(\n",
        "    learning_rate=0.35,  # Too high learning rate\n",
        "    n_estimators=30,  # Very few trees\n",
        "    max_depth=1,  # Very shallow trees\n",
        "    min_samples_split=50,  # High min_samples_split\n",
        "    min_samples_leaf=20,  # High min_samples_leaf\n",
        "    subsample=0.4,  # Aggressive subsampling\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = gbm.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpCbFTQ3XoOD",
        "outputId": "ed2ae754-6830-4735-d026-129d11bbf631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.8700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Gradient Boosting Model with improved parameters\n",
        "gbm = GradientBoostingClassifier(\n",
        "    learning_rate=0.1,  # Lower learning rate for better generalization\n",
        "    n_estimators=100,  # Increase number of trees\n",
        "    max_depth=4,  # Deeper trees to capture more complexity\n",
        "    min_samples_split=10,  # Reduce min_samples_split to allow more splits\n",
        "    min_samples_leaf=5,  # Reduce min_samples_leaf to allow more leaf nodes\n",
        "    subsample=0.8,  # Less aggressive subsampling\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = gbm.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dY_0o3uYIdm",
        "outputId": "14ab88c1-a97b-4775-d743-ffc59c64b48f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OVERFITTING SITUATION**"
      ],
      "metadata": {
        "id": "FKPndVWpYs-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Gradient Boosting Model with overfitting conditions\n",
        "gbm = GradientBoostingClassifier(\n",
        "    learning_rate=0.005,  # Too low learning rate\n",
        "    n_estimators=600,  # Too many trees\n",
        "    max_depth=7,  # Too deep trees\n",
        "    min_samples_split=2,  # No constraint on splits\n",
        "    min_samples_leaf=1,  # No constraint on leaf nodes\n",
        "    subsample=1.0,  # No subsampling (full dataset used)\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on training and test sets\n",
        "y_train_pred = gbm.predict(X_train)\n",
        "y_test_pred = gbm.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76RHXhA9YklX",
        "outputId": "93f3cb04-d932-4019-b5d7-6f1bb363f9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0000\n",
            "Test Accuracy: 0.8950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Gradient Boosting Model with better generalization\n",
        "gbm = GradientBoostingClassifier(\n",
        "    learning_rate=0.1,  # Moderate learning rate\n",
        "    n_estimators=200,  # Reasonable number of trees\n",
        "    max_depth=5,  # Balanced depth to avoid overfitting\n",
        "    min_samples_split=10,  # Constrain splits to prevent overfitting\n",
        "    min_samples_leaf=5,  # Prevents overly complex leaf nodes\n",
        "    subsample=0.8,  # Introduce subsampling for regularization\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on training and test sets\n",
        "y_train_pred = gbm.predict(X_train)\n",
        "y_test_pred = gbm.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0BWZ32IY-4w",
        "outputId": "5c6d8d48-ea54-498d-d8fa-970cf5bb1fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 1.0000\n",
            "Test Accuracy: 0.9100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cQjX8i8XbW_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBOOST ALGORITHM**"
      ],
      "metadata": {
        "id": "-i2bQ1rvbXud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Gradient Boosting model\n",
        "gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = gbm.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(f'GBM Accuracy: {accuracy_score(y_test, y_pred):.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTcG-E6Zbcdm",
        "outputId": "db464a8b-9e82-47af-b357-c53b05d9159b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GBM Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Train XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(f'XGBoost Accuracy: {accuracy_score(y_test, y_pred_xgb):.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ8XAHFwbf4A",
        "outputId": "56ffc509-862b-447b-a25c-e6b801150ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGB ALGORITHM**"
      ],
      "metadata": {
        "id": "SlWe_dgbAaZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define XGBoost Classifier with optimized parameters\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=150,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.2,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.7,\n",
        "    reg_lambda=5,\n",
        "    reg_alpha=1,\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = xgb_clf.score(X_test, y_test)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG9mN_r2AaC-",
        "outputId": "f21508f3-f223-4de2-8561-3ddde6d49cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 95.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'alpha': [0, 0.1, 1, 5, 10],  # L1 values\n",
        "    'lambda': [1, 10, 50, 100]    # L2 values\n",
        "}\n",
        "\n",
        "# Initialize model\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100)\n",
        "\n",
        "# Grid search\n",
        "grid_search = GridSearchCV(xgb_model, param_grid, cv=3, scoring='r2')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX5xl_hOKtN2",
        "outputId": "be0fadd2-1950-46ef-d100-7d2fb4d17fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'alpha': 0.1, 'lambda': 50}\n"
          ]
        }
      ]
    }
  ]
}